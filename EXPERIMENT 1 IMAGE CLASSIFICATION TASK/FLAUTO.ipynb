{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3969db0-3d2a-4211-8144-0d212092c40c",
   "metadata": {},
   "source": [
    "<h2>Project Name: FLAUTO: Federated Learning with Automated\n",
    "Dual-Level Hyperparameter Tuning  </h2>\n",
    "<h3> Written by Rakib Ul Haque and supervised by Dr. Panos P. Markopoulos </h3>\n",
    "<h4> Email: panagiotis.markopoulos@utsa.edu</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c0fa9-e576-4e02-9b11-2e57894dadd4",
   "metadata": {},
   "source": [
    "<H1> FLAUTO </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473cd34e",
   "metadata": {
    "id": "473cd34e",
    "outputId": "9b4bf5da-8a0b-45fc-e2e7-042b3d2ebf1f"
   },
   "outputs": [],
   "source": [
    "# Librearies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from collections import Counter\n",
    "import random\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import queue\n",
    "from collections import deque\n",
    "from torch import Tensor\n",
    "from typing import Type\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ce049",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "738ce049",
    "outputId": "16e7254f-7275-464e-e7cb-552f9fb6ce34"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(), #This transformation converts a PIL (Python Imaging Library) Image or numpy.ndarray (with shape (H x W x C) in the range [0, 255]) into a PyTorch tensor of shape (C x H x W) in the range [0.0, 1.0]. It essentially rearranges the dimensions of the image data and scales it to a float value between 0 and 1.\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "# train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "subset_dataset = torch.load('val_dataset.pth',weights_only=False)\n",
    "remaining_dataset = torch.load('test_dataset.pth',weights_only=False)\n",
    "\n",
    "# Create DataLoaders\n",
    "val_loader = DataLoader(subset_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(remaining_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a07007-73ec-4701-a6a8-8a7893655af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the distribution of dataset\n",
    "def print_distribution(client_data):\n",
    "    # Check distribution\n",
    "    for l, client_data_value in enumerate(client_data):\n",
    "        print(f\"Client {l + 1} data size: {len(client_data_value)}\")\n",
    "        class_counts = {j: 0 for j in range(10)}\n",
    "        for _, label in client_data_value:\n",
    "            class_counts[label] += 1\n",
    "        print(f\"Class distribution: {class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2700fb3",
   "metadata": {
    "id": "f2700fb3"
   },
   "outputs": [],
   "source": [
    "# necessary functions\n",
    "def Print(string, dictionary):\n",
    "    first_key = next(iter(dictionary))\n",
    "    first_value = dictionary[first_key]\n",
    "    print(f\"{string}:{first_key}: {first_value[0][0]}\\n\")\n",
    "\n",
    "\n",
    "def model_deviation_function(w_i, w_f):\n",
    "    model_deviation = 0\n",
    "    for k in w_i.keys():\n",
    "        model_deviation += torch.linalg.norm(w_f[k].to(torch.float) - w_i[k].to(torch.float)) / (torch.linalg.norm(w_i[k].to(torch.float)) +1)\n",
    "    #print(model_deviation.item())\n",
    "    return model_deviation.item()\n",
    "    \n",
    "\n",
    "def forbinus_norm_function(w_i):\n",
    "    value = 0\n",
    "    for k in w_i.keys():\n",
    "        value += torch.linalg.norm(w_i[k])\n",
    "    return value.item()\n",
    "\n",
    "def accuracy(outp, target):\n",
    "    \"\"\"Computes accuracy\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(outp, dim=1)\n",
    "        correct = pred.eq(target).float().sum().item()\n",
    "        return 100.0 * correct / target.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c94d4-d23d-4419-9cb1-06963e315c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary graphs\n",
    "\n",
    "#===clietn rmd graphs\n",
    "def c_rmd_line_graph_generator(data, x_gg, x_label, y_label, graph_title, filename ):\n",
    "    x_g = list(range(1, x_gg + 1))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(2.84, 2.22))\n",
    "\n",
    "    # Plot the data\n",
    "    ax1.plot(x_g, data, color='red')\n",
    "\n",
    "    # Labeling the axes\n",
    "    ax1.set_xlabel(x_label, fontsize=8, labelpad=0)\n",
    "    ax1.set_ylabel(y_label, fontsize=8, labelpad=0)\n",
    "\n",
    "    # Setting the range for x and y axes\n",
    "    ax1.set_ylim(0, 1.6)\n",
    "    ax1.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6])\n",
    "    ax1.set_xticks(range(1, x_gg + 1))\n",
    "\n",
    "    # Adding grid lines\n",
    "    grid_color = 'grey'\n",
    "    ax1.grid(True, axis='x', color=grid_color)\n",
    "    ax1.spines['left'].set_color(grid_color)\n",
    "    ax1.spines['bottom'].set_color(grid_color)\n",
    "\n",
    "    # Removing the top and right spines\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    # Show the left and bottom spines in gray\n",
    "    ax1.tick_params(axis='x', labelsize=7)  # Reduced tick label font size to 7\n",
    "    ax1.tick_params(axis='y', labelsize=7)  # Reduced tick label font size to 7\n",
    "\n",
    "    # Adding title\n",
    "    plt.title(graph_title, fontsize=8)\n",
    "\n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot to a PDF file\n",
    "    save_path = filename + \".pdf\"\n",
    "    plt.savefig(save_path, dpi=1000)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#===batch size graphs\n",
    "def DY_b_line_graph_generator(data1, data2, x_gg, x_label, y_label1, graph_title, filename):\n",
    "    x_g = list(range(1, x_gg + 1))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(2.84, 2.22))\n",
    "\n",
    "    # Add text above the graph\n",
    "    text_x = 0.41\n",
    "    text_y = 0.84\n",
    "    text = 'β update criteria met'\n",
    "    text_obj = plt.figtext(text_x, text_y, text, ha='center', va='top', fontsize=7,\n",
    "                           bbox=dict(facecolor=(1, 1, 1, 0.8), edgecolor='none'))\n",
    "\n",
    "    # Plotting the learning rates\n",
    "    ax1.set_xlabel(str(x_label), fontsize=8, labelpad=0)\n",
    "    ax1.set_ylabel(str(y_label1), color='black', fontsize=8, labelpad=0)\n",
    "    ax1.plot(x_g, data1, color='blue')  # Dashed line for data1\n",
    "    ax1.tick_params(axis='y', labelcolor='black', labelsize=7)\n",
    "    ax1.tick_params(axis='x', labelsize=7)\n",
    "\n",
    "    # Setting y-axis limits and ticks\n",
    "    ax1.set_ylim(0, 300)\n",
    "    ax1.set_yticks([0, 50, 100, 150, 200, 250, 300])\n",
    "    ax1.set_xticks(range(1, x_gg + 1))\n",
    "\n",
    "    # Adding grid lines\n",
    "    grid_color = 'grey'\n",
    "    #ax1.grid(True, axis='x', color=grid_color)\n",
    "    plt.gca().spines['left'].set_color(grid_color)\n",
    "    plt.gca().spines['bottom'].set_color(grid_color)\n",
    "\n",
    "    # Removing the top and right spines\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    # Get the position of the text center in display coordinates\n",
    "    bbox = text_obj.get_window_extent(renderer=fig.canvas.get_renderer())\n",
    "    bbox_data = bbox.transformed(fig.dpi_scale_trans.inverted())\n",
    "\n",
    "    # Convert the text center coordinates to data coordinates\n",
    "    text_x_data, text_y_data = 1.5, 130\n",
    "\n",
    "    # Plotting vertical lines for data2 and markers\n",
    "    for i in range(len(data2)):\n",
    "        if data2[i] == 1:\n",
    "            ax1.axvline(x=x_g[i], color='red', linestyle='--', linewidth=1.5)\n",
    "            #ax1.plot(x_g[i], data1[i])  # Add marker\n",
    "\n",
    "    # Adding title\n",
    "    plt.title(graph_title, fontsize=8)\n",
    "\n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot to a PDF file\n",
    "    save_path = filename + \".png\"\n",
    "    plt.savefig(save_path, dpi=1000)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#===rmd graphs\n",
    "def d_rmd_line_graph_generator(c_data, s_data, x_gg, x_label, y_label, c_label, s_label, filename):\n",
    "    x_g = list(range(1, x_gg + 1))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(2.84, 2.22))\n",
    "\n",
    "    # Plotting the data\n",
    "    ax1.plot(x_g, c_data, label=str(c_label), color='red',linestyle='--')  # Plot train accuracy\n",
    "    ax1.plot(x_g, s_data, label=str(s_label), color='blue',linestyle='-')  # Plot train accuracy\n",
    "\n",
    "    # Labeling the axes\n",
    "    ax1.set_xlabel(str(x_label), fontsize=8,labelpad=0)\n",
    "    ax1.set_ylabel(str(y_label), fontsize=8,labelpad=0)\n",
    "\n",
    "    # Setting the range for x and y axes\n",
    "    ax1.set_ylim(0, 12)\n",
    "    ax1.set_yticks([0, 2, 4, 6, 8, 10, 12])\n",
    "    #ax1.set_xticks(range(0, x_gg + 1,5))\n",
    "    ax1.set_xticks([ 1, 5, 10, 15, 20, 25, 30])\n",
    "\n",
    "    # Adding grid lines\n",
    "    grid_color = 'grey'\n",
    "    ax1.grid(True, axis='x', color=grid_color)\n",
    "    ax1.spines['left'].set_color(grid_color)\n",
    "    ax1.spines['bottom'].set_color(grid_color)\n",
    "\n",
    "    # Removing the top and right spines\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    # Show the left and bottom spines in gray\n",
    "    ax1.tick_params(axis='x', labelsize=7)  # Reduced tick label font size to 7\n",
    "    ax1.tick_params(axis='y', labelsize=7)  # Reduced tick label font size to 7\n",
    "\n",
    "    # Adding legend\n",
    "    ax1.legend(fontsize=7)\n",
    "    plt.title('Server rmd & average client rmd vs round', fontsize=8)\n",
    "\n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot to a PDF file\n",
    "    save_path = filename + \".pdf\"\n",
    "    plt.savefig(save_path, dpi=1000)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#====epoch graphs\n",
    "def epoch_line_graph_generator(data, x_gg, x_label, y_label, filename):\n",
    "    x_g = list(range(1, x_gg + 1))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(2.84, 2.22))\n",
    "\n",
    "    # Plot the data\n",
    "    ax1.plot(x_g, data, color='red')  # Plot train accuracy\n",
    "\n",
    "    # Labeling the axes\n",
    "    ax1.set_xlabel(str(x_label), fontsize=8)\n",
    "    ax1.set_ylabel(str(y_label), fontsize=8)\n",
    "\n",
    "    ax1.set_ylim(1, 6)\n",
    "    ax1.set_yticks([1, 2, 3, 4, 5,6])\n",
    "    ax1.set_xticks([1, 5, 10, 15, 20, 25, 30])\n",
    "\n",
    "    # Adding grid lines\n",
    "    grid_color = 'grey'\n",
    "    ax1.grid(True, axis='x', color=grid_color)\n",
    "    ax1.spines['left'].set_color(grid_color)\n",
    "    ax1.spines['bottom'].set_color(grid_color)\n",
    "\n",
    "    # Removing the top and right spines\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    # Set font size for ticks\n",
    "    ax1.tick_params(axis='x', labelsize=7)  # X-axis tick label font size\n",
    "    ax1.tick_params(axis='y', labelsize=7)  # Y-axis tick label font size\n",
    "\n",
    "    # Add title with font size 7\n",
    "    plt.title('Average epoch per client vs round', fontsize=8)\n",
    "\n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot to a PDF file\n",
    "    save_path = filename + \".pdf\"\n",
    "    plt.savefig(save_path, dpi=1000)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#====batch size grpahs\n",
    "def a_m_b_line_graph_generator(data, x_gg, x_label, y_label, filename):\n",
    "    x_g = list(range(1, x_gg + 1))\n",
    "\n",
    "    # Specify desired xtick positions\n",
    "    xticks = [1, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "    # Ensure x_g includes all specified xtick positions\n",
    "    # Filter data to match xticks\n",
    "    x_ticks_with_data = [i for i in xticks if i <= len(data)]\n",
    "    filtered_data = [data[i-1] for i in x_ticks_with_data]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(2.84, 2.22))\n",
    "\n",
    "    # Plot the data without markers\n",
    "    ax1.plot(x_g, data, color='red')  # Plot train accuracy\n",
    "\n",
    "    # Add markers only at the specified x-tick positions\n",
    "    #ax1.scatter(x_ticks_with_data, filtered_data, color='tab:blue')  # Plot markers at specified positions\n",
    "\n",
    "    # Labeling the axes\n",
    "    ax1.set_xlabel(str(x_label), fontsize=8, labelpad=0)\n",
    "    ax1.set_ylabel(str(y_label), fontsize=8, labelpad=0)\n",
    "\n",
    "    ax1.set_ylim(0, 300)\n",
    "    ax1.set_yticks([0, 30, 60, 90, 120, 150])\n",
    "    ax1.set_xticks(xticks)  # Set x-ticks to desired positions\n",
    "\n",
    "    # Adding grid lines\n",
    "    grid_color = 'grey'\n",
    "    ax1.grid(True, axis='x', color=grid_color)\n",
    "    ax1.spines['left'].set_color(grid_color)\n",
    "    ax1.spines['bottom'].set_color(grid_color)\n",
    "\n",
    "    # Removing the top and right spines\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    # Show the left and bottom spines in gray\n",
    "    ax1.tick_params(axis='x', labelsize=7)  # Reduced tick label font size to 7\n",
    "    ax1.tick_params(axis='y', labelsize=7)  # Reduced tick label font size to 7\n",
    "\n",
    "    plt.title('Average max β per client vs rounds', fontsize=8)\n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot to a PDF file\n",
    "    save_path = filename + \".pdf\"\n",
    "    plt.savefig(save_path, dpi=1000)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#===== learning rate tuning graphs\n",
    "def DY_LR_line_graph_generator(data1, data2, x_gg, x_label, y_label1, filename):\n",
    "    x_g = list(range(1, x_gg + 1))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(2.84, 2.22))\n",
    "\n",
    "    # Add text above the graph\n",
    "    text_x = 0.55\n",
    "    text_y = 0.5\n",
    "    plt.figtext(text_x, text_y, 'λ update criteria met', ha='center', va='top', fontsize=7,\n",
    "                bbox=dict(facecolor=(1, 1, 1, .7), edgecolor='none'))\n",
    "\n",
    "    # Plotting the learning rates\n",
    "    ax1.set_xlabel(str(x_label), fontsize=8, labelpad=0)\n",
    "    ax1.set_ylabel(str(y_label1), fontsize=8, labelpad=0)\n",
    "    ax1.plot(x_g, data1, color='blue')  # Removed label to exclude it from the legend\n",
    "    #ax1.tick_params(axis='y', labelcolor='black', labelsize=7)\n",
    "    ax1.tick_params(axis='y', labelsize=7)\n",
    "    ax1.tick_params(axis='x', labelsize=7)\n",
    "\n",
    "    # Setting y-axis limits and ticks\n",
    "    ax1.set_ylim(0, 0.006)\n",
    "    ax1.set_yticks([0.0000,  0.0012, 0.0024, 0.0036, 0.0048, 0.006])\n",
    "    # ax1.set_yticks([0,  0.005, 0.008, 0.01, 0.015, 0.02])\n",
    "    ax1.set_xticks([1, 5, 10, 15, 20, 25, 30])\n",
    "\n",
    "    # Adding grid lines\n",
    "    grid_color = 'grey'\n",
    "    ax1.spines['left'].set_color(grid_color)\n",
    "    ax1.spines['bottom'].set_color(grid_color)\n",
    "    # Removing the top and right spines\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    # Plotting vertical lines for data2 and markers\n",
    "    for i in range(len(data2)):\n",
    "        if data2[i] == 1:\n",
    "            ax1.axvline(x=x_g[i], color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "    # Add title\n",
    "    plt.title('λ & λ update criteria vs round', fontsize=8)\n",
    "\n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot to a PNG file\n",
    "    save_path = filename + \".png\"\n",
    "    plt.savefig(save_path, dpi=1000)\n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3ffbe",
   "metadata": {
    "id": "e0a3ffbe"
   },
   "outputs": [],
   "source": [
    "#====CNN model\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)  # Adjust input size here\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10)  # Add a linear layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = self.relu4(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu5(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d43d8",
   "metadata": {
    "id": "833d43d8"
   },
   "outputs": [],
   "source": [
    "#train functions\n",
    "\n",
    "def train(i_weights, epochs, data_c, lea_rate,max_LR, nsv, mome, wd, cli,roun, batch_ss, max_b, epoch_count,client_limit,epoch_flag):\n",
    "    global opti\n",
    "    rmd_pe=[]\n",
    "    loss_pe=[]\n",
    "    batch_list=[]\n",
    "    \n",
    "    batch_list_context=[]\n",
    "    batch_list_context.append(0)\n",
    "    \n",
    "    c_limit=client_limit\n",
    "    rmd_change=0\n",
    "    \n",
    "    batch_s=batch_ss\n",
    "    le_rate=lea_rate\n",
    "    \n",
    "    Step_Size_b=(max_b - batch_s) / (client_limit)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(data_c, batch_size=batch_s, shuffle=True, drop_last=True)\n",
    "    rmd_pe.append(0)\n",
    "    aa,ll=test(i_weights,train_loader)\n",
    "    loss_pe.append(ll)\n",
    "    # print(\"epoch zero loss:\",ll,\"rmd: 0\")\n",
    "\n",
    "    local_model = model().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if opti==\"adam\":\n",
    "        optimizer = torch.optim.Adam(local_model.parameters(), lr=le_rate)\n",
    "    elif opti==\"sgd\":\n",
    "        optimizer = torch.optim.SGD(local_model.parameters(), lr=le_rate)\n",
    "        \n",
    "    local_model.load_state_dict(i_weights)\n",
    "\n",
    "    local_model.train()  # Set the model to training mode\n",
    "\n",
    "    # initial weights cathing and printing\n",
    "    initial_weights = {k: v.clone() for k, v in local_model.state_dict().items()}\n",
    "     \n",
    "    # Training loop\n",
    "    for epoch in range(1,epochs+1):\n",
    "\n",
    "        #epoch_b.at[(roun, epoch), f\"c_{cli}\"]=batch_s\n",
    "\n",
    "        epoch_count=epoch_count+1\n",
    "        epoch_flag=epoch_flag+1\n",
    "        # gradients_this_epoch = {}\n",
    "        total_samples = 0\n",
    "        total_loss=0\n",
    "        correct_samples = 0\n",
    "        \n",
    "        batch_list.append(batch_s)\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward + backward + optimize\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            #torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)  # Get the index of the maximum value in outputs (predicted class)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_samples += predicted.eq(labels).sum().item()\n",
    "\n",
    "        if(total_samples!=0 and len(train_loader)!=0):\n",
    "            epoch_accuracy = 100 * correct_samples / total_samples\n",
    "            epoch_loss = total_loss / len(train_loader)\n",
    "        else:\n",
    "            epoch_accuracy = 100 * correct_samples / (total_samples+1)\n",
    "            epoch_loss = total_loss / (len(train_loader)+1)\n",
    "\n",
    "\n",
    "        fff_weights = {k: v.clone() for k, v in local_model.state_dict().items()}\n",
    "        modev_pe=model_deviation_function(initial_weights,fff_weights)\n",
    "        \n",
    "        print(f\"Round {roun}, client {cli},  Epoch {epoch }, rmd: {modev_pe} Learning rate: {le_rate}, batch size: {batch_s}, Loss: {epoch_loss},  accuracy: {epoch_accuracy:.2f}%, \")\n",
    "\n",
    "        rmd_pe.append(modev_pe)\n",
    "        loss_pe.append(epoch_loss)\n",
    "        \n",
    "        if epoch>1:\n",
    "            rmd_change=abs(rmd_pe[epoch]-rmd_pe[epoch-1])/rmd_pe[epoch-1]\n",
    "        \n",
    "        batch_list_context.append( ( (rmd_pe[epoch] <1) and (rmd_change*100) <20 ) or (loss_pe[epoch] >= loss_pe[epoch-1]) )\n",
    "        # print(\"batch size change condition: \",((rmd_pe[epoch] <1) and (rmd_change*100) <20 ) or (loss_pe[epoch] >= loss_pe[epoch-1]))\n",
    "        if( ((rmd_pe[epoch] <1) and (rmd_change*100) <20 ) or (loss_pe[epoch] >= loss_pe[epoch-1]) ):\n",
    "            c_limit=c_limit-1\n",
    "            if(c_limit<=0):\n",
    "                break\n",
    "            batch_s= round(batch_s + Step_Size_b)\n",
    "            if batch_s >= max_b:\n",
    "                batch_s = max_b\n",
    "            # print(\"updated batch :\",batch_s)\n",
    "            train_loader = torch.utils.data.DataLoader(data_c, batch_size=batch_s, shuffle=True, drop_last=True)\n",
    "            \n",
    "    rmd_pe = rmd_pe[1:]\n",
    "    c_rmd_line_graph_generator(rmd_pe, len(rmd_pe),\n",
    "                               \"epoch\",\n",
    "                               f\"rmd\",\n",
    "                               f'rmd vs epoch (c={cli}, r={roun})',\n",
    "                               f\"client no {cli} rmd at round {roun} accross epoch\")\n",
    "    #c_b_line_graph_generator(batch_list, len(batch_list), \"epoch\", f\"β\", f\"client {cli} β at round {roun}\", f\"client no {cli} batch at round {roun} accross epoch\")\n",
    "    #c_b_c_line_graph_generator(batch_list_context, len(batch_list_context), \"epoch\", f\"β update criteria\", f\"client no {cli} batch update criteria\", f\"client no {cli} batch change condition at round {roun} accross epoch\")\n",
    "    DY_b_line_graph_generator(batch_list, batch_list_context[1:], len(batch_list),\n",
    "                              \"epoch\",\n",
    "                              f\"β\",\n",
    "                              f'β & β update criteria vs epoch (c={cli}, r={roun})',\n",
    "                              f\"client no {cli}, batch and batch change condition at round {roun} accross epoch dual_y_axis_plot_\")\n",
    "    #c_rmd_line_graph_generator(rmd_pe, len(rmd_pe), \"epoch\", f\"client {cli} rmd\", f\"client {cli} rmd at round {roun} accross epoch\", f\"client no {cli} rmd at round {roun} accross epoch\")\n",
    "    #c_b_line_graph_generator(batch_list, len(batch_list), \"epoch\", f\"client {cli} β\", f\"client {cli} batch at round {roun} accross epoch\", f\"client no {cli} batch at round {roun} accross epoch\")\n",
    "    #c_b_c_line_graph_generator(batch_list_context, len(batch_list_context), \"epoch\", f\"client {cli} β change condition\", f\"client no {cli} batch change condition at round {roun} accross epoch\", f\"client no {cli} batch change condition at round {roun} accross epoch\")\n",
    "    \n",
    "    max_batch=max(batch_list)\n",
    "    total_epoch_batch=sum(batch_list)\n",
    "    avg_epoch_batch=sum(batch_list)/len(batch_list)\n",
    "    avg_epoch_rmd=sum(rmd_pe)/len(rmd_pe)    \n",
    "\n",
    "    if nsv==0:\n",
    "        f_weights = {k: v.clone() for k, v in local_model.state_dict().items()}\n",
    "    else:\n",
    "        temp_f_weights = {k: v.clone() for k, v in local_model.state_dict().items()}\n",
    "        f_weights = add_gaussian_noise_to_dict(temp_f_weights, nsv)\n",
    "        \n",
    "    modev=model_deviation_function(initial_weights,f_weights)\n",
    "\n",
    "    return epoch_accuracy,epoch_loss, f_weights, epoch_count, epoch_flag, max_batch, total_epoch_batch, avg_epoch_batch, avg_epoch_rmd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5cef1c",
   "metadata": {
    "id": "9d5cef1c"
   },
   "outputs": [],
   "source": [
    "#test\n",
    "def test(w,data):\n",
    "    lmodel = model().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()  # Assuming a classification task\n",
    "    #optimizer = optim.SGD(lmodel.parameters(), lr=min_LR)\n",
    "    lmodel.load_state_dict(w)\n",
    "    lmodel.eval()\n",
    "\n",
    "    #checking the weights\n",
    "    tw = lmodel.state_dict()\n",
    "\n",
    "    # Evaluation phase for test set\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for j, data in enumerate(test_loader, 0):\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            out = lmodel(images)\n",
    "            # Calculate loss\n",
    "            loss = criterion(out, labels)\n",
    "            loss_list.append(loss.item())\n",
    "            #calculate accuracy\n",
    "            acc = accuracy(out, labels)\n",
    "            acc_list.append(acc)\n",
    "    test_loss = np.mean(loss_list)\n",
    "    test_accuracy = np.mean(acc_list)\n",
    "    return test_accuracy, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d35af3",
   "metadata": {
    "id": "c0d35af3"
   },
   "outputs": [],
   "source": [
    "#=== Fl structure\n",
    "def federated_learning(i_w, c, p, r, e, data_client, min_LR,max_LR, min_b,max_b, global_Step_Size_LR, server_limit, mome, wd, distribution, alpha_v, noise_strength_value, straggler_prob,client_limit):\n",
    "    counter=0\n",
    "    global_model.load_state_dict(i_w)\n",
    "\n",
    "    model_weights_queue = deque(maxlen=2)\n",
    "\n",
    "    # List of clients\n",
    "    clients = list(range(1, c+1))\n",
    "    \n",
    "\n",
    "    epoch_count=0\n",
    "    \n",
    "    #loop for round\n",
    "    for i in range(1,r+1):\n",
    "\n",
    "        round_LR.append(min_LR)\n",
    "\n",
    "        r_time_s = time.time()\n",
    "\n",
    "        epoch_flag=0\n",
    "\n",
    "        client_counter=0\n",
    "\n",
    "        i_w = {k: v.clone() for k, v in global_model.state_dict().items()}\n",
    "\n",
    "        all_gradients={}\n",
    "        all_final_weights={}\n",
    "\n",
    "        train_accuracy_list=[]\n",
    "        train_loss_list=[]\n",
    "\n",
    "        # Initialize the dictionary to track non-stragglers\n",
    "        non_stragglers = {client: 1 for client in clients}\n",
    "\n",
    "        # Randomly select clients\n",
    "        selected_clients = random.sample(clients, p)\n",
    "        #print(f\"Round: {i}, Total client: {c}, Participating client {p}, Selected clients: {selected_clients}\")\n",
    "\n",
    "        participating_client_list.append(selected_clients)\n",
    "\n",
    "        # Check for stragglers and update the non_stragglers dictionary\n",
    "        straggler_count = 0\n",
    "        for client in selected_clients:\n",
    "            if random.uniform(0, 1) < straggler_prob:\n",
    "                non_stragglers[client] = 0\n",
    "                straggler_count += 1\n",
    "\n",
    "\n",
    "        # Ensure at least one non-straggler\n",
    "        if straggler_count == len(selected_clients):\n",
    "            # Randomly choose one client to be a non-straggler\n",
    "            non_straggler_client = random.choice(selected_clients)\n",
    "            non_stragglers[non_straggler_client] = 1\n",
    " \n",
    "        c_max_batch=0\n",
    "        c_total_epoch_batch=0\n",
    "        c_avg_epoch_batch=0\n",
    "        c_avg_epoch_rmd=0\n",
    "        \n",
    "        #loop for client\n",
    "        for j, data in enumerate(data_client):\n",
    "\n",
    "            if(j+1 in selected_clients and non_stragglers[j+1]):\n",
    "\n",
    "                client_counter=client_counter+1\n",
    "\n",
    "                #train model\n",
    "                train_accuracy, train_loss, c_f_weights, epoch_count,epoch_flag, max_batch, total_epoch_batch, avg_epoch_batch, avg_epoch_rmd=train(i_w, e, data, min_LR, max_LR, noise_strength_value, mome, wd,j+1,i,min_b,max_b, epoch_count,client_limit,epoch_flag)\n",
    "                \n",
    "                c_max_batch= c_max_batch + max_batch \n",
    "                c_total_epoch_batch = c_total_epoch_batch + total_epoch_batch \n",
    "                c_avg_epoch_batch = c_avg_epoch_batch + avg_epoch_batch \n",
    "                c_avg_epoch_rmd = c_avg_epoch_rmd + avg_epoch_rmd\n",
    "\n",
    "                train_accuracy_list.append(train_accuracy)\n",
    "                train_loss_list.append(train_loss)\n",
    "\n",
    "                # Accumulate weights for the selected client\n",
    "                for param_name, param_grad in c_f_weights.items():\n",
    "                    if param_name in all_final_weights:\n",
    "                        all_final_weights[param_name] += param_grad\n",
    "                    else:\n",
    "                        all_final_weights[param_name] = param_grad\n",
    "\n",
    "            else:\n",
    "                print(f\"client {j+1} is not selectecd\")\n",
    "        \n",
    "        c_max_b_round_list.append(c_max_batch/p)\n",
    "        c_t_b_round_list.append(c_total_epoch_batch/p)\n",
    "        c_e_b_round_list.append(c_avg_epoch_batch/p)\n",
    "        c_e_rmd_round_list.append(c_avg_epoch_rmd/p)\n",
    "        \n",
    "        round_epoch.append(epoch_flag)\n",
    "        \n",
    "        averaged_train_loss=sum(train_loss_list)/len(train_loss_list)\n",
    "        averaged_train_accuracy=sum(train_accuracy_list)/len(train_accuracy_list)\n",
    "        \n",
    "        for param_name in all_final_weights:\n",
    "            all_final_weights[param_name] = all_final_weights[param_name].float() / client_counter\n",
    "\n",
    "        #validation_code\n",
    "        val_accuracy, val_loss=test(all_final_weights, val_loader)\n",
    "\n",
    "        #test code\n",
    "        test_accuracy,test_loss=test( all_final_weights, test_loader)\n",
    "        #print(f\"model's Round: {i}, test accuracy of : {test_accuracy}, test loss of : {test_loss}, train accuracy of : {averaged_train_accuracy} \\n\\n\")\n",
    "\n",
    "        #model deviation code\n",
    "        model_deviation=model_deviation_function(i_w,  all_final_weights)\n",
    "        model_weights_queue.append(all_final_weights)\n",
    "\n",
    "        print(f\"model's Round: {i}, Rmd: {model_deviation}, test accuracy: {test_accuracy}, test loss: {test_loss}, train accuracy: {averaged_train_accuracy} \\n\\n\")\n",
    "\n",
    "        # if distribution==\"iid\":\n",
    "        iid_accuracy.append(averaged_train_accuracy)\n",
    "        iid_loss.append(averaged_train_loss)\n",
    "        iid_val_loss.append(val_loss)\n",
    "        iid_val_accuracy.append(val_accuracy)\n",
    "        iid_test_loss.append(test_loss)\n",
    "        iid_test_accuracy.append(test_accuracy)\n",
    "        iid_model_deviation.append(model_deviation)\n",
    "\n",
    "        if server_limit > 0:\n",
    "            round_LR_context.append( (iid_val_loss[i] > iid_val_loss[i-1]) and (min_LR > 0.0001) )\n",
    "            if (iid_val_loss[i] > iid_val_loss[i-1]) and (min_LR > 0.0001):\n",
    "                max_LR=min_LR\n",
    "                min_LR=round(min_LR - global_Step_Size_LR,4)\n",
    "                min_LR=min_LR\n",
    "                server_limit=server_limit-1\n",
    "                global_Step_Size_LR = (max_LR - min_LR) / (2 ** server_limit)\n",
    "                all_final_weights = model_weights_queue.popleft()\n",
    "                model_weights_queue.clear()\n",
    "            elif iid_val_loss[i] <= iid_val_loss[i-1]:\n",
    "                min_LR=round(min_LR + global_Step_Size_LR,4)\n",
    "                if min_LR>=max_LR:\n",
    "                    min_LR=max_LR\n",
    "                    \n",
    "        global_model.load_state_dict(all_final_weights)\n",
    "        print(\"round: \", i, \" completed \", \" total epoch: \", epoch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda6c6a",
   "metadata": {
    "id": "7fda6c6a",
    "outputId": "e742f4e1-68fa-46c0-e2f3-c1f0718aa1d5"
   },
   "outputs": [],
   "source": [
    "# main code\n",
    "\n",
    "#===========================Parameters model==============================================================\n",
    "client_no=20\n",
    "participating_client=20\n",
    "epochs=5\n",
    "\n",
    "momentum=0.95\n",
    "weight_decay=5e-4\n",
    "round_no=50\n",
    "\n",
    "global_epoch=(epochs * round_no)\n",
    "rounds = list(range(0, round_no+1))\n",
    "distributions = \"iid\" #or non_iid \n",
    "data_class=10\n",
    "alpha='infinity' #or 0.5 \n",
    "client_limit=4 #4 is used to generate all the graphs \n",
    "server_limit=4 #4 is used to generate al the graphs\n",
    "\n",
    "\n",
    "opti=\"adam\" # or sgd\n",
    "\n",
    "\n",
    "c_max_b_round_list=[]\n",
    "c_e_b_round_list=[]\n",
    "c_t_b_round_list=[]\n",
    "c_e_rmd_round_list=[]\n",
    "\n",
    "min_LR=0.0001\n",
    "min_b=64\n",
    "max_LR=0.09\n",
    "max_b=256\n",
    "\n",
    "global_Step_Size_LR = (max_LR - min_LR) / (( 2 ** server_limit))\n",
    "participating_client_list=[]\n",
    "p_c_l=[]\n",
    "iid_accuracy=[]\n",
    "iid_loss=[]\n",
    "iid_test_accuracy=[]\n",
    "iid_test_loss=[]\n",
    "iid_val_accuracy=[]\n",
    "iid_val_loss=[]\n",
    "iid_model_deviation=[]\n",
    "iid_model_deviation.append(0)\n",
    "round_epoch=[]\n",
    "iid_epoch_test_accuracy=[]\n",
    "iid_epoch_test_loss=[]\n",
    "round_LR=[]\n",
    "round_LR_context=[]\n",
    "round_LR_context.append(0)\n",
    "\n",
    "# Create a list to store the row index\n",
    "row_index = []\n",
    "# Generate row index data\n",
    "for round_num in range(1, round_no + 1):\n",
    "    for epoch in range(0, epochs):\n",
    "        row_index.append((round_num, epoch))\n",
    "\n",
    "# Create a DataFrame filled with zeros\n",
    "epoch_b = pd.DataFrame(0, index=pd.MultiIndex.from_tuples(row_index, names=['r', 'e']), columns=[f\"c_{i}\" for i in range(1, client_no)])\n",
    "epoch_b_context = pd.DataFrame('-', index=pd.MultiIndex.from_tuples(row_index, names=['r', 'e']), columns=[f\"c_{i}\" for i in range(1, client_no)])\n",
    "\n",
    "noise_strength = 0\n",
    "straggler_prob_value = 0\n",
    "\n",
    "roun = [f\"{i}\" for i in range(round_no+1)]\n",
    "global_model = model().to(device)\n",
    "\n",
    "file_path = \"s_cnn.pth\"\n",
    "initial_weights=torch.load(file_path, weights_only=True)\n",
    "Print(\"Model's initial weights\", initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8ad92",
   "metadata": {
    "id": "f3f8ad92",
    "outputId": "c47c1ff3-964e-4c31-a6c4-204ca70f66d6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading training data\n",
    "\n",
    "# client_datasets_IID = distribute_dataset_equally(train_dataset,client_no)\n",
    "# Load client_datasets from a file\n",
    "if distributions == 'iid':\n",
    "    with open('20_client_datasets_IID.pkl', 'rb') as f:\n",
    "        clients = pickle.load(f)\n",
    "\n",
    "elif distributions == 'non_iid' and alpha==0.5:\n",
    "    with open('20_client_datasets_non_IID_0_5.pkl', 'rb') as f:\n",
    "        clients = pickle.load(f)\n",
    "    \n",
    "elif distributions == 'non_iid' and alpha==0.2:\n",
    "    with open('20_client_datasets_non_IID_0_2.pkl', 'rb') as f:\n",
    "        clients = pickle.load(f)\n",
    "        \n",
    "print(\"client_datasets loaded successfully.\")\n",
    "print_distribution(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2faa2",
   "metadata": {
    "id": "4fc2faa2",
    "outputId": "a4aa802b-68a1-4b36-ccd7-12c09378e84f"
   },
   "outputs": [],
   "source": [
    "\n",
    "#reound zero\n",
    "\n",
    "train_accuracy_list=[]\n",
    "train_loss_list=[]\n",
    "for j, data in enumerate(clients):\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=min_b, shuffle=True, drop_last=True)\n",
    "    train_accuracy, train_loss=test(initial_weights, train_loader)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "iid_accuracy.append(sum(train_accuracy_list)/len(train_accuracy_list))\n",
    "iid_loss.append(sum(train_loss_list)/len(train_loss_list))\n",
    "\n",
    "\n",
    "val_accuracy,val_loss=test(initial_weights,val_loader)\n",
    "iid_val_accuracy.append(val_accuracy)\n",
    "iid_val_loss.append(val_loss)\n",
    "\n",
    "test_accuracy,test_loss=test(initial_weights,test_loader)\n",
    "iid_test_accuracy.append(test_accuracy)\n",
    "iid_test_loss.append(test_loss)\n",
    "\n",
    "Print(\"initial_weights\", initial_weights)\n",
    "print(f' train accuracy: {train_accuracy}\\n train_loss: {train_loss}\\n test_accuracy: {test_accuracy}\\n test_loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NJ_CpP0b9OUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJ_CpP0b9OUo",
    "outputId": "961d3fb1-5fee-4497-be83-fff67f5e10e3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "federated_learning(initial_weights, client_no, participating_client, round_no, epochs, clients, min_LR, max_LR, min_b, max_b, global_Step_Size_LR, server_limit, momentum, weight_decay, distributions, str(alpha), noise_strength, straggler_prob_value,client_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ca551-fc24-4fcd-bae5-09e55f8cea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating grpahs\n",
    "\n",
    "avg_round_epoch = [item / 20 for item in round_epoch]\n",
    "epoch_line_graph_generator(avg_round_epoch, len(avg_round_epoch), \"round\", \"epoch count\", \"------averaged number of epoch run across rounds\")\n",
    "\n",
    "#average max beta\n",
    "a_m_b_line_graph_generator(c_max_b_round_list, len(c_max_b_round_list), \"round\", \"β\", \"------------average clients max β across rounds\")\n",
    "\n",
    "#dual rmd\n",
    "d_rmd_line_graph_generator(c_e_rmd_round_list, iid_model_deviation[1:], len(c_e_rmd_round_list), \"round\", \"rmd\", \"average client rmd\", \"server rmd\", \"-------dual_Y_axis_plot_for_rmd\")\n",
    "\n",
    "#learning rate\n",
    "DY_LR_line_graph_generator(round_LR, round_LR_context[1:], len(round_LR), \"round\", \"λ\", \"-----dual_Y_axis_plot_for_lamda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a54df9-f32f-43c1-98a3-3eb1e064641f",
   "metadata": {},
   "source": [
    "<H1>Rasults</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=\"CNN, c=\"+str(client_no)+ \", p=\"+ str(participating_client)+ \", e=\"+ str(epochs)+ \", r=\"+ str(round_no) +\", lr=\"+ str(min_LR) + \", bs=\" + str(min_b)\n",
    "roun = [f\"{i}\" for i in range(round_no+1)]\n",
    "roun_int = [int(value) for value in roun]\n",
    "rounds = list(range(0, round_no+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccfce9-3294-4338-a185-86acde76af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collection1 = pd.DataFrame({'round': list(range(1,len(round_LR)+1)), 'LR': round_LR, 'LR_c': ro_LR_c, 're': round_epoch, 'rae': avg_round_epoch, 'max_average_batch': c_max_b_round_list, 'average_ce_batch': c_e_b_round_list, 'ct_batch': c_t_b_round_list, 'ce_rmd':c_e_rmd_round_list})\n",
    "# data_collection1.to_csv(f'Method_1_Scratch_relavent_data.csv', index=False)\n",
    "\n",
    "roun_int = [int(value) for value in roun]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(roun_int, iid_model_deviation, label=\"rmd\", marker='o',color='red')  # Plot test accuracy\n",
    "# plt.plot(roun_int, iid_accuracy, label=\"Train accuracy\", marker='x',color='black')  # Plot train accuracy\n",
    "\n",
    "# Labeling the axes and the plot\n",
    "plt.xlabel(\"Round\", fontsize=15)\n",
    "plt.ylabel(\"rmd\", fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "# Set x-axis and y-axis label intervals to a difference of 10\n",
    "plt.xticks(range(0, max(roun_int) + 1, 5))\n",
    "# plt.yticks(range(0.0, 0.5))\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "# Show grid if you prefer\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.title(tag)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5ca8e-c0a9-478f-bb35-2fcaf16ddbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "roun_int = [int(value) for value in roun]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(roun_int, iid_test_accuracy, label=\"Test accuracy\", marker='o',color='red')  # Plot test accuracy\n",
    "plt.plot(roun_int, iid_accuracy, label=\"Train accuracy\", marker='x',color='black')  # Plot train accuracy\n",
    "\n",
    "# Labeling the axes and the plot\n",
    "plt.xlabel(\"Round\", fontsize=15)\n",
    "plt.ylabel(\"Accuracy\", fontsize=15)\n",
    "plt.legend()\n",
    "\n",
    "# Set x-axis and y-axis label intervals to a difference of 10\n",
    "plt.xticks(range(0, max(roun_int) + 1, 10))\n",
    "plt.yticks(range(0, 101, 10))\n",
    "\n",
    "# Show grid if you prefer\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.title(tag)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b564104-e29f-4edb-8a18-7116318eb8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection = pd.DataFrame({'round': roun_int, 'train_accuracy': iid_accuracy, 'test_accuracy': iid_test_accuracy, 'train_loss': iid_loss, 'test_loss': iid_test_loss, 'rmd': iid_model_deviation, 'val_accuracy': iid_val_accuracy, 'val_loss': iid_val_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e58db-e9ff-4700-89aa-33f4d00c7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "data_collection.to_csv(f'Method_1__Scratched_Adam_1_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b75e70-7e43-48b5-b89a-dba50f12a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce8362-b0f6-42a2-966d-1d858d1ed82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round_epoch)\n",
    "\n",
    "x_g= range(1,len(round_epoch)+1)\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.plot(x_g, round_epoch, marker='o',color='red')  # Plot train accuracy\n",
    "\n",
    "\n",
    "plt.xlabel(\"Rounds\",  fontsize=24)\n",
    "plt.ylabel(\"Epoch number\",  fontsize=24)\n",
    "plt.legend()\n",
    "plt.yticks(range(0, 101, 10))\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2023d9-8fbf-48fa-8ef6-561c6dbd3be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60fd278-552b-4336-b721-19b23a01093a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7a26882b",
    "f40fd883",
    "bef90546"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
