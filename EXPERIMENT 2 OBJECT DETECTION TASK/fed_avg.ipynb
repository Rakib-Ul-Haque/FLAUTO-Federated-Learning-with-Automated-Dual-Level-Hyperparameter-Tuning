{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a58cf1b-3d2f-46a3-9d78-7cb0d19e1aef",
   "metadata": {},
   "source": [
    "<h4> This code is part of FLAUTO. It implements FedAdap. Date: 01/09/2025 </h4>\n",
    "<h4> Contact: rakibul.haque@utsa.edu </h4>  \n",
    "<h4> Cite as: R. U. Haque and P. Markopoulos,\"Federated Learning with Automated Dual-Level Hyperparameter Tuning\", 2025 <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624d84c-82b5-41c9-a0c2-48168ce61cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import os\n",
    "# from IPython.display import clear_output\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "# from IPython.display import clear_output\n",
    "import copy\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# print function\n",
    "def Print(string, dictionary):\n",
    "    first_key = next(iter(dictionary))\n",
    "    first_value = dictionary[first_key]\n",
    "    print(f\"{string}:{first_key}: {first_value[0][0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf81979-6d5d-416a-b023-c3c6bb3459d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path identification\n",
    "def on_train_epoch_end(trainer):\n",
    "    \"\"\"Custom logic for additional metrics logging at the end of each training epoch.\"\"\"\n",
    "    global path\n",
    "    path=trainer.csv\n",
    "\n",
    "# define function to add data from another DataFrame\n",
    "def add_data_to_client(client_id, new_data):\n",
    "    global clients\n",
    "    if client_id in clients:\n",
    "        # Append new data to the client's DataFrame\n",
    "        clients[client_id] = pd.concat([clients[client_id], new_data], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Client {client_id} does not exist.\")\n",
    "\n",
    "\n",
    "# deleting run folder for saving spaces\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove the folder and all its contents\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' deleted successfully!\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n",
    "\n",
    "\n",
    "#averaging the weihgts\n",
    "\n",
    "def average_weights_function(dicts):\n",
    "    # Initialize an empty dictionary to store the summed weights\n",
    "    summed_weights = {}\n",
    "    \n",
    "    # Initialize an empty dictionary to keep track of how many times each key is seen\n",
    "    key_occurrences = {}\n",
    "    \n",
    "    # Iterate through all the dictionaries\n",
    "    for d in dicts:\n",
    "        for key, value in d.items():\n",
    "            if key in summed_weights:\n",
    "                summed_weights[key] += value\n",
    "                key_occurrences[key] += 1\n",
    "            else:\n",
    "                summed_weights[key] = value\n",
    "                key_occurrences[key] = 1\n",
    "    \n",
    "    # Create a dictionary to store the final averaged weights\n",
    "    averaged_weights = {}\n",
    "    \n",
    "    # Iterate through the summed weights and divide by the number of occurrences for each key\n",
    "    for key, value in summed_weights.items():\n",
    "        if key_occurrences[key] > 1:\n",
    "            averaged_weights[key] = value / key_occurrences[key]\n",
    "        else:\n",
    "            averaged_weights[key] = value  # If only present in one dict, keep as is\n",
    "    \n",
    "    return averaged_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da9dd6-54f8-470e-9f84-38d905de25fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training( i_w, E, r, c, l_rate):\n",
    "    #declear local model\n",
    "    global path, count_e\n",
    "    local_model=YOLO(\"initial_weights.pt\").to(device)\n",
    "    local_model.load_state_dict(i_w)\n",
    "    print(local_model.info())\n",
    "    total_loss=[]\n",
    "    flag=0\n",
    "    le_rate=l_rate\n",
    "    checking_weights = local_model.state_dict()\n",
    "    Print(f\"Client {c} functions weights\", checking_weights)\n",
    "    \n",
    "    #epochs\n",
    "    for e in range(0,E):\n",
    "        count_e=count_e+1\n",
    "        local_model.add_callback(\"on_train_epoch_end\", on_train_epoch_end)\n",
    "        local_model.train(data=f\"{fl_a}/{set_up}/c{c}.yaml\", project=f\"{dst_folder}/train/round_{r}_client_{c}/{e}\", workers=0, epochs=1, imgsz=512, split='train', lr0=le_rate, batch=4, optimizer=opti, val=True, device=0, warmup_epochs=0)\n",
    "\n",
    "        #collecting results\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        df.columns = df.columns.str.strip()\n",
    "        t_loss= df['val/box_loss'] + df['val/cls_loss'] + df['val/dfl_loss']\n",
    "        total_loss.append(t_loss.iloc[0])\n",
    "    \n",
    "    #checking initial weights\n",
    "    Print(f\"Client {c} initial weights\", i_w)\n",
    "    #colleting final weights\n",
    "    client_final_weights = {k: v.clone() for k, v in local_model.state_dict().items()}#local_model.state_dict()\n",
    "    Print(f\"Client {c} final weights\",client_final_weights)    \n",
    "    #clear_output(wait=False)\n",
    "    return client_final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da9572-ea24-4675-896f-7741d1c2be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(i_w, C, P, R, E, learning_rate, b_size):\n",
    "\n",
    "    # declearning global validtion dictionary\n",
    "    global global_model\n",
    "    global validation_dict\n",
    "    global dst_folder\n",
    "    global device\n",
    "    global_model.load_state_dict(i_w)\n",
    "    #global average_weights\n",
    "    #loop for round\n",
    "    for r in range(1,R+1):\n",
    "                \n",
    "        models=[]\n",
    "        #global_model = YOLO(f\"Fed_Avg/weights/round_{r-1}_weighs\").to(device)\n",
    "        i_w = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(\"Model's initial weights\", i_w)\n",
    "        \n",
    "        #loop for clients\n",
    "        for c in range(1,C+1):\n",
    "\n",
    "            #training\n",
    "            clients_weight=training(i_w, E, r, c, learning_rate)\n",
    "            models.append(clients_weight)\n",
    "        \n",
    "        \n",
    "        average_weights=average_weights_function(models)\n",
    "        #torch.save(average_weights, f'{dst_folder}/weights/round_{r}_weighs.pt')\n",
    "        os.makedirs(os.path.join(dst_folder, \"weights\"), exist_ok=True)  # Creates both Fed_Avg and weights if needed\n",
    "        # Now you can save the weights as usual:\n",
    "        torch.save(average_weights, f'{dst_folder}/weights/after_round_{r}_weighs.pt')\n",
    "\n",
    "        global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        global_model.load_state_dict(average_weights)\n",
    "        val_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "        val_model.load_state_dict(average_weights)\n",
    "        #global_model = load_model_weights_partial(\"yolov8n-obb.yaml\", average_weights, device)\n",
    "             \n",
    "        #chceking averaged weights\n",
    "        c_weight= {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "        Print(f\"updated global model after round {r}\",c_weight)\n",
    "        \n",
    "        #performing round validations\n",
    "        validation_results = val_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_{r}\", workers=0, imgsz=512, batch=4, split='val', device=0)\n",
    "        #save validation results into dict \n",
    "        validation_dict[f\"round_{r}\"] = validation_results\n",
    "        \n",
    "        #Print(\"updated global model\",i_w)\n",
    "        \n",
    "        print(\"round\", r, \"completed\")\n",
    "        # clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301c849-0acc-4824-964f-372d8b40cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================Parameters==============================================================\n",
    "round_no=30\n",
    "client_no=4\n",
    "participating_client=client_no\n",
    "learning_rate=0.0001\n",
    "batch_size=4\n",
    "epochs=5\n",
    "opti='SGD'\n",
    "count_e=0\n",
    "\n",
    "#===========other variables=============================================\n",
    "validation_dict = {}\n",
    "\n",
    "\n",
    "fl_a=\"yaml\"\n",
    "set_up=\"IID\"\n",
    "# set_up=\"limited_data\"\n",
    "\n",
    "\n",
    "forname=set_up\n",
    "\n",
    "dst_folder = f\"{fl_a}_{forname}_fed_avg_{learning_rate}_{opti}\"\n",
    "# dst_folder = f\"Fed_Avg\"\n",
    "delete_folder(dst_folder)\n",
    "\n",
    "path=\"\"\n",
    "\n",
    "#client results storage\n",
    "clients = {f'client_{i}': pd.DataFrame(columns=['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\n",
    "       'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)',\n",
    "       'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\n",
    "       'lr/pg0', 'lr/pg1', 'lr/pg2']) for i in range(1,10)}\n",
    "\n",
    "#===================================loading the saved weight list====================================================\n",
    "global_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "global_model.info()\n",
    "initial_weights = {k: v.clone() for k, v in global_model.state_dict().items()}#global_model.state_dict()\n",
    "print(len(initial_weights))\n",
    "Print(\"Model's initial weights\", initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd8725-e3e6-403a-be10-276a8b98c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "#server validation rounds\n",
    "validation_results = l_model.val(data=f\"{fl_a}/c5.yaml\", project=f\"{dst_folder}/val/round_0\", imgsz=512, batch=4,split='val', device=0, workers=0)\n",
    "validation_dict[\"round_0\"] = validation_results\n",
    "print(validation_results)\n",
    "\n",
    "#=================================================================client_1====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c1.yaml\", project=f\"{dst_folder}/train/round_0_client_1\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "\n",
    "#=================================================================client_2====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c2.yaml\", project=f\"{dst_folder}/train/round_0_client_2\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "\n",
    "\n",
    "#=================================================================client_3====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c3.yaml\", project=f\"{dst_folder}/train/round_0_client_3\", imgsz=512, batch=4, split='train',device=0, workers=0)\n",
    "\n",
    "\n",
    "#=================================================================client_4====================\n",
    "l_model = YOLO(\"initial_weights.pt\").to(device)\n",
    "l_model.val(data=f\"{fl_a}/{set_up}/c4.yaml\", project=f\"{dst_folder}/train/round_0_client_4\", imgsz=512, batch=4, split='train', device=0, workers=0)\n",
    "#clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1305bcb-8b95-444d-953b-f3101592a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters 3,085,440 parameters, 3,085,424 gradients\n",
    "federated_learning(initial_weights, client_no, participating_client, round_no, epochs, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285db511-3ec7-487a-9b70-5117594e702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"global epoch\", count_e)\n",
    "\n",
    "# Convert the dict to a serializable format\n",
    "def dict_to_serializable(d):\n",
    "    serializable_dict = {}\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, (int, float, str, list, dict)):\n",
    "            serializable_dict[key] = value\n",
    "        else:\n",
    "            serializable_dict[key] = str(value)  # Convert non-serializable types to string\n",
    "    return serializable_dict\n",
    "\n",
    "# Save as JSON\n",
    "save_dir = dst_folder\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_path = os.path.join(save_dir, 'validation_dict.json')\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(dict_to_serializable(validation_dict), f, indent=4)\n",
    "\n",
    "print(f\"Validation dictionary saved to {file_path}\")\n",
    "\n",
    "file_path = os.path.join(save_dir, 'validation_dict.json')\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, 'r') as f:\n",
    "    loaded_dict = json.load(f)\n",
    "\n",
    "# Print the loaded dictionary\n",
    "print(\"Validation dictionary loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
